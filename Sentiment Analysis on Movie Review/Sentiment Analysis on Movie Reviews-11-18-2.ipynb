{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/11 Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "\"There's a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"\n",
    "\n",
    "The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon's Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.\n",
    "\n",
    "Kaggle is hosting this competition for the machine learning community to use for fun and practice. This competition was inspired by the work of Socher et al [2]. We encourage participants to explore the accompanying (and dare we say, fantastic) website that accompanies the paper:\n",
    "\n",
    "http://nlp.stanford.edu/sentiment/\n",
    "\n",
    "There you will find have source code, a live demo, and even an online interface to help train the model.\n",
    "\n",
    "[1] Pang and L. Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In ACL, pages 115–124.\n",
    "\n",
    "[2] Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative \n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### tsv는 tab 기반\n",
    "\n",
    "# sep => seperate\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase\n",
       "PhraseId                                                               \n",
       "156061          8545  An intermittently pleasing but mostly routine ...\n",
       "156062          8545  An intermittently pleasing but mostly routine ...\n",
       "156063          8545                                                 An\n",
       "156064          8545  intermittently pleasing but mostly routine effort\n",
       "156065          8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase(Origin)\"] = train[\"Phrase\"].copy()\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase(Origin)\"] = test[\"Phrase\"].copy()\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can not recommend it'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(phrase):\n",
    "    phrase = phrase.replace(\"ca n't\", \"can not\")\n",
    "    phrase = phrase.replace(\"n't\", \"not\")\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "phrase = \"ca n't recommend it\"\n",
    "\n",
    "clean_text(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase\"] = train[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase\"] = test[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/keonpark/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/keonpark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/keonpark/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer   ## 어근찾아주는 기능\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "stemmer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stemming...:  42%|████▏     | 65161/156060 [00:07<00:10, 8734.80it/s]"
     ]
    }
   ],
   "source": [
    "def stem_phrase(phrase):\n",
    "    words = phrase.split(\" \")\n",
    "    stemmed_phrase = [stemmer.stem(w) for w in words]\n",
    "    return \" \".join(stemmed_phrase)\n",
    "\n",
    "tqdm.pandas(desc=\"Stemming...\")\n",
    "train[\"Phrase\"] = train[\"Phrase\"].progress_apply(stem_phrase)\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test[\"Phrase\"] = test[\"Phrase\"].progress_apply(stem_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer\n",
    "\n",
    "def transorm_pos(pos):\n",
    "    if 'V' in pos:\n",
    "        return 'v'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatizing(phrase):\n",
    "    words = word_tokenize(phrase)\n",
    "    word_pos = pos_tag(words)\n",
    "    \n",
    "    filtered = (lemmatizer.lemmatize(word, transorm_pos(word_pos)) for word in words)\n",
    "    \n",
    "    return \" \".join(filtered)\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Bag of words, vectorization\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "\n",
    "# # max_features: 우리가 단어의 개수를 지정함.\n",
    "# # 빈번하게 나오는 단어를 많이 뽑고, 빈도가 낮은 단어는 뽑지 않음\n",
    "# # 최대 1000개만 뽑으라고 지정\n",
    "# # 문장을 단어로 뽑아줌.\n",
    "# # binary option: 해당 단어가 존재유무로 체크\n",
    "\n",
    "# ngram을 늘릴때는 max_feature를 늘리는 것이 좋다.\n",
    "# ngram을 늘리면 단어(숙어) 단위가 늘어나니까\n",
    "\n",
    "# vectorizer = CountVectorizer(max_features=15000, ngram_range=(1, 2), binary=True)\n",
    "# vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='char')\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer\n",
    "- fit\n",
    "- transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단어의 개수를 \n",
    "\n",
    "X_train = vectorizer.transform(train[\"Phrase\"])\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train[0:100].toarray(), columns=vocabulary).head()\n",
    "\n",
    "## row: 전체 데이터\n",
    "## column: voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test[\"Phrase\"])\n",
    "\n",
    "print(X_test.shape)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"Sentiment\"\n",
    "\n",
    "y_train = train[label_name]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "seed = 43\n",
    "\n",
    "model = SGDClassifier(random_state=seed)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "\n",
    "# print(\"Score = {0:5f}\".format(score))\n",
    "\n",
    "## 기존의 cross_val_score를 두 단계로 나눈 것\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# base meaning:  K-fold cross validation is one way to improve over the holdout method. \n",
    "# The data set is divided into k subsets, and the holdout method is repeated k times. \n",
    "# Each time, one of the k subsets is used as the test set and the other k-1 subsets are put together to form a training set.\n",
    "# 기존의 cv만 사용했을 때보다 kaggle score와 비슷하게 나옴\n",
    "# => crosss validation의 정확도(?)가 좀 더 높아지는 효과라고 볼 수 있음\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "y_predict = cross_val_predict(model, X_train, y_train,\n",
    "                              cv=kfold, groups=train[\"SentenceId\"])\n",
    "\n",
    "print(y_predict.shape)\n",
    "y_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_train, y_predict)\n",
    "\n",
    "print(\"Score = {0:.5f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본이 훼손되니까 복사해서 사용\n",
    "result = train.copy()\n",
    "result[\"Sentiment(predict)\"] = y_predict\n",
    "# predict한 Sentiment와 train의 실제 Sentiment와의 차이를 통해 모델의 예측차를 확인\n",
    "result[\"Distance\"] = np.abs(result[\"Sentiment\"] - result[\"Sentiment(predict)\"])\n",
    "result = result.sort_values(by=\"Distance\", ascending=False)\n",
    "\n",
    "print(result.shape)\n",
    "result[[\"Phrase\", \"Sentiment(predict)\", \"Distance\"]].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(vocabulary).to_csv(\"vocabular.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stunning 단어 개선\n",
    "\n",
    "result.loc[132656]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"SampleSubmission.csv\", index_col=\"PhraseId\")\n",
    "\n",
    "submission[\"Sentiment\"] = predictions\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline-script.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDGClassifier\n",
    "\n",
    "Machine Learning\n",
    "- Supervised Learning(SL)\n",
    "- Unsupervised Learning(UL)\n",
    "- Reinforcement Learning\n",
    "\n",
    "SL: feature(O), label(O)\n",
    "UL: feature(O), label(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "삼성전자 주식 예측 예시\n",
    "- cross validation을 사용할 경우, 시간적인 고려가 되지 않음\n",
    "- ex) 2016년도 주식을 가지고, 2015년도 주식을 예측하는 경우\n",
    "\n",
    "문장의 경우\n",
    "- train 데이터와 test 데이터의 셋이 연관성도 없고 voca set이 다름.\n",
    "- SentenceId 기준으로 중복시키지 않도록 처리\n",
    "\n",
    "0.60 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
