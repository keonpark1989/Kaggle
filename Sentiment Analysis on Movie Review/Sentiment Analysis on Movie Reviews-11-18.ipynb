{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/11 Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "\"There's a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"\n",
    "\n",
    "The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon's Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.\n",
    "\n",
    "Kaggle is hosting this competition for the machine learning community to use for fun and practice. This competition was inspired by the work of Socher et al [2]. We encourage participants to explore the accompanying (and dare we say, fantastic) website that accompanies the paper:\n",
    "\n",
    "http://nlp.stanford.edu/sentiment/\n",
    "\n",
    "There you will find have source code, a live demo, and even an online interface to help train the model.\n",
    "\n",
    "[1] Pang and L. Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In ACL, pages 115–124.\n",
    "\n",
    "[2] Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative \n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### tsv는 tab 기반\n",
    "\n",
    "# sep => seperate\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase\n",
       "PhraseId                                                               \n",
       "156061          8545  An intermittently pleasing but mostly routine ...\n",
       "156062          8545  An intermittently pleasing but mostly routine ...\n",
       "156063          8545                                                 An\n",
       "156064          8545  intermittently pleasing but mostly routine effort\n",
       "156065          8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase(Origin)\"] = train[\"Phrase\"].copy()\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase(Origin)\"] = test[\"Phrase\"].copy()\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can not recommend it'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(phrase):\n",
    "    phrase = phrase.replace(\"ca n't\", \"can not\")\n",
    "    phrase = phrase.replace(\"n't\", \"not\")\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "phrase = \"ca n't recommend it\"\n",
    "\n",
    "clean_text(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase\"] = train[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase\"] = test[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# stemmer = SnowballStemmer('english')\n",
    "# stemmer\n",
    "\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stem_phrase(phrase):\n",
    "#     words = phrase.split(\" \")\n",
    "#     stemmed_phrase = [stemmer.stem(w) for w in words]\n",
    "#     return \" \".join(stemmed_phrase)\n",
    "\n",
    "# tqdm.pandas(desc=\"Stemming...\")\n",
    "# train[\"Phrase\"] = train[\"Phrase\"].progress_apply(stem_phrase)\n",
    "\n",
    "# print(train.shape)\n",
    "# train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test[\"Phrase\"] = test[\"Phrase\"].progress_apply(stem_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer\n",
    "\n",
    "def transorm_pos(pos):\n",
    "    if 'V' in pos:\n",
    "        return 'v'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatizing(phrase):\n",
    "    words = word_tokenize(phrase)\n",
    "    word_pos = pos_tag(words)\n",
    "    \n",
    "    filtered = (lemmatizer.lemmatize(word, transorm_pos(word_pos)) for word in words)\n",
    "    \n",
    "    return \" \".join(filtered)\n",
    "\n",
    "train[\"Phrase\"] = train[\"Phrase\"].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapade demonstrating the adage t...</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapade demonstrating the adage t...</td>\n",
       "      <td>2</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapade demonstrating the adage t...   \n",
       "2                  1  A series of escapade demonstrating the adage t...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment                                     Phrase(Origin)  \n",
       "PhraseId                                                                \n",
       "1                 1  A series of escapades demonstrating the adage ...  \n",
       "2                 2  A series of escapades demonstrating the adage ...  \n",
       "3                 2                                           A series  \n",
       "4                 2                                                  A  \n",
       "5                 2                                             series  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=15000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None,\n",
       "        stop_words=['disappointments'], strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words, vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "\n",
    "# max_features: 우리가 단어의 개수를 지정함.\n",
    "# 빈번하게 나오는 단어를 많이 뽑고, 빈도가 낮은 단어는 뽑지 않음\n",
    "# 최대 1000개만 뽑으라고 지정\n",
    "# 문장을 단어로 뽑아줌.\n",
    "# binary option: 해당 단어가 존재유무로 체크\n",
    "\n",
    "stop_words = ['disappointments']\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=15000, ngram_range=(1, 2), binary=True, stop_words=stop_words)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer\n",
    "- fit\n",
    "- transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=15000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None,\n",
       "        stop_words=['disappointments'], strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 15000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<156060x15000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1257306 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 단어의 개수를 \n",
    "\n",
    "X_train = vectorizer.transform(train[\"Phrase\"])\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000', '10', '10 minute', '10 or', '10 year']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>10 minute</th>\n",
       "      <th>10 or</th>\n",
       "      <th>10 year</th>\n",
       "      <th>100</th>\n",
       "      <th>100 minute</th>\n",
       "      <th>100 year</th>\n",
       "      <th>101</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>yu</th>\n",
       "      <th>zany</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zinger</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  10 minute  10 or  10 year  100  100 minute  100 year  101  11  \\\n",
       "0    0   0          0      0        0    0           0         0    0   0   \n",
       "1    0   0          0      0        0    0           0         0    0   0   \n",
       "2    0   0          0      0        0    0           0         0    0   0   \n",
       "3    0   0          0      0        0    0           0         0    0   0   \n",
       "4    0   0          0      0        0    0           0         0    0   0   \n",
       "\n",
       "   ...   yu  zany  zeal  zealand  zero  zhang  zinger  zippy  zombie  zone  \n",
       "0  ...    0     0     0        0     0      0       0      0       0     0  \n",
       "1  ...    0     0     0        0     0      0       0      0       0     0  \n",
       "2  ...    0     0     0        0     0      0       0      0       0     0  \n",
       "3  ...    0     0     0        0     0      0       0      0       0     0  \n",
       "4  ...    0     0     0        0     0      0       0      0       0     0  \n",
       "\n",
       "[5 rows x 15000 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train[0:100].toarray(), columns=vocabulary).head()\n",
    "\n",
    "## row: 전체 데이터\n",
    "## column: voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 15000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<66292x15000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 416627 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test[\"Phrase\"])\n",
    "\n",
    "print(X_test.shape)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "5    2\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = \"Sentiment\"\n",
    "\n",
    "y_train = train[label_name]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=43, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "seed = 43\n",
    "\n",
    "model = SGDClassifier(random_state=seed)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "\n",
    "# print(\"Score = {0:5f}\".format(score))\n",
    "\n",
    "## 기존의 cross_val_score를 두 단계로 나눈 것\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# 기존의 cv만 사용했을 때보다 kaggle score와 비슷하게 나옴\n",
    "# => crosss validation의 정확도(?)가 좀 더 높아지는 효과라고 볼 수 있음\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "y_predict = cross_val_predict(model, X_train, y_train,\n",
    "                              cv=kfold, groups=train[\"SentenceId\"])\n",
    "\n",
    "print(y_predict.shape)\n",
    "y_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.58685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_train, y_predict)\n",
    "\n",
    "print(\"Score = {0:.5f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment(predict)</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142370</th>\n",
       "      <td>The performance are so overstated , the effect...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53284</th>\n",
       "      <td>attempt to mine laugh from a genre -- the gang...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37375</th>\n",
       "      <td>is the best Star Trek movie in a long time .</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73472</th>\n",
       "      <td>is -RRB- a fascinating character , and deserve...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37374</th>\n",
       "      <td>This is the best Star Trek movie in a long time .</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117415</th>\n",
       "      <td>'s unfortunate that Wallace , who wrote Gibson...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143437</th>\n",
       "      <td>seems altogether too slight to be called any k...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66532</th>\n",
       "      <td>one of the saddest action hero performance eve...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130641</th>\n",
       "      <td>The gag that fly at such a furiously funny pac...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72813</th>\n",
       "      <td>One of the most unpleasant thing the studio ha...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89657</th>\n",
       "      <td>profane and exploitative a the most offensive ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99222</th>\n",
       "      <td>presented in such a lousy way , complete with ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51504</th>\n",
       "      <td>A no-holds-barred cinematic treat .</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126778</th>\n",
       "      <td>that we really have not had a good cheesy B-mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142763</th>\n",
       "      <td>I can not remember the last time I saw an audi...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11777</th>\n",
       "      <td>, this is the opposite of a truly magical movie .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142764</th>\n",
       "      <td>can not remember the last time I saw an audien...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>convinced I could keep a family of five blind ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>'m convinced I could keep a family of five bli...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36194</th>\n",
       "      <td>'m convinced I could keep a family of five bli...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11778</th>\n",
       "      <td>this is the opposite of a truly magical movie .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>offer the none-too-original premise that every...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119896</th>\n",
       "      <td>the era of the intelligent , well-made B movie...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89656</th>\n",
       "      <td>, profane and exploitative a the most offensiv...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37376</th>\n",
       "      <td>is the best Star Trek movie in a long time</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>a scummy ripoff of David Cronenberg 's brillia...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35158</th>\n",
       "      <td>It would be great to see this turd squashed un...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105911</th>\n",
       "      <td>Ben Kingsley is truly funny , playing a kind o...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59241</th>\n",
       "      <td>manipulating our collective fear without besto...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42394</th>\n",
       "      <td>'s nothing remotely triumphant about this moti...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101006</th>\n",
       "      <td>'s so tedious that it make you forgive every f...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78647</th>\n",
       "      <td>feel a if -LRB- there 's -RRB- a choke leash a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>diminishing his stature from Oscar-winning mas...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101007</th>\n",
       "      <td>'s so tedious that it make you forgive every f...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61625</th>\n",
       "      <td>There is no substitute for on-screen chemistry...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78648</th>\n",
       "      <td>feel a if -LRB- there 's -RRB- a choke leash a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113299</th>\n",
       "      <td>One of those film that started with a great pr...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107525</th>\n",
       "      <td>Leave it to the French to truly capture the te...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16722</th>\n",
       "      <td>is talented enough and charismatic enough to m...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133345</th>\n",
       "      <td>, this modern mob music drama never fails to f...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119884</th>\n",
       "      <td>arrived for an incongruous summer playoff , de...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>After you laugh once -LRB- maybe twice -RRB- ,...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22212</th>\n",
       "      <td>this disappointed by a movie in a long time</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22211</th>\n",
       "      <td>been this disappointed by a movie in a long time</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92731</th>\n",
       "      <td>As improbable a this premise may seem , Abbass...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35159</th>\n",
       "      <td>would be great to see this turd squashed under...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136958</th>\n",
       "      <td>a an intellectual exercise -- an unpleasant de...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35160</th>\n",
       "      <td>would be great to see this turd squashed under...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145063</th>\n",
       "      <td>Diaz wear out her welcome in her most charmles...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35161</th>\n",
       "      <td>be great to see this turd squashed under a tru...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96215</th>\n",
       "      <td>chore to sit through -- despite some first-rat...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60437</th>\n",
       "      <td>combined with so much first-rate talent ... co...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96214</th>\n",
       "      <td>a chore to sit through -- despite some first-r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130091</th>\n",
       "      <td>will no doubt rally to it cause , trotting out...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101017</th>\n",
       "      <td>fake , dishonest , entertaining and , ultimate...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>The thought of watching this film with an audi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134201</th>\n",
       "      <td>at this time , with this cast , this movie is ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146672</th>\n",
       "      <td>The thought of watching this film with an audi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>of the most appealing movie ever made about an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14964</th>\n",
       "      <td>can such a cold movie claim to express warmth ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "142370    The performance are so overstated , the effect...   \n",
       "53284     attempt to mine laugh from a genre -- the gang...   \n",
       "37375          is the best Star Trek movie in a long time .   \n",
       "73472     is -RRB- a fascinating character , and deserve...   \n",
       "37374     This is the best Star Trek movie in a long time .   \n",
       "117415    's unfortunate that Wallace , who wrote Gibson...   \n",
       "143437    seems altogether too slight to be called any k...   \n",
       "66532     one of the saddest action hero performance eve...   \n",
       "130641    The gag that fly at such a furiously funny pac...   \n",
       "72813     One of the most unpleasant thing the studio ha...   \n",
       "89657     profane and exploitative a the most offensive ...   \n",
       "99222     presented in such a lousy way , complete with ...   \n",
       "51504                   A no-holds-barred cinematic treat .   \n",
       "126778    that we really have not had a good cheesy B-mo...   \n",
       "142763    I can not remember the last time I saw an audi...   \n",
       "11777     , this is the opposite of a truly magical movie .   \n",
       "142764    can not remember the last time I saw an audien...   \n",
       "36196     convinced I could keep a family of five blind ...   \n",
       "36195     'm convinced I could keep a family of five bli...   \n",
       "36194     'm convinced I could keep a family of five bli...   \n",
       "11778       this is the opposite of a truly magical movie .   \n",
       "14831     offer the none-too-original premise that every...   \n",
       "119896    the era of the intelligent , well-made B movie...   \n",
       "89656     , profane and exploitative a the most offensiv...   \n",
       "37376            is the best Star Trek movie in a long time   \n",
       "7024      a scummy ripoff of David Cronenberg 's brillia...   \n",
       "35158     It would be great to see this turd squashed un...   \n",
       "105911    Ben Kingsley is truly funny , playing a kind o...   \n",
       "59241     manipulating our collective fear without besto...   \n",
       "42394     's nothing remotely triumphant about this moti...   \n",
       "...                                                     ...   \n",
       "101006    's so tedious that it make you forgive every f...   \n",
       "78647     feel a if -LRB- there 's -RRB- a choke leash a...   \n",
       "21468     diminishing his stature from Oscar-winning mas...   \n",
       "101007    's so tedious that it make you forgive every f...   \n",
       "61625     There is no substitute for on-screen chemistry...   \n",
       "78648     feel a if -LRB- there 's -RRB- a choke leash a...   \n",
       "113299    One of those film that started with a great pr...   \n",
       "107525    Leave it to the French to truly capture the te...   \n",
       "16722     is talented enough and charismatic enough to m...   \n",
       "133345    , this modern mob music drama never fails to f...   \n",
       "119884    arrived for an incongruous summer playoff , de...   \n",
       "149978    After you laugh once -LRB- maybe twice -RRB- ,...   \n",
       "22212           this disappointed by a movie in a long time   \n",
       "22211      been this disappointed by a movie in a long time   \n",
       "92731     As improbable a this premise may seem , Abbass...   \n",
       "35159     would be great to see this turd squashed under...   \n",
       "136958    a an intellectual exercise -- an unpleasant de...   \n",
       "35160     would be great to see this turd squashed under...   \n",
       "145063    Diaz wear out her welcome in her most charmles...   \n",
       "35161     be great to see this turd squashed under a tru...   \n",
       "96215     chore to sit through -- despite some first-rat...   \n",
       "60437     combined with so much first-rate talent ... co...   \n",
       "96214     a chore to sit through -- despite some first-r...   \n",
       "130091    will no doubt rally to it cause , trotting out...   \n",
       "101017    fake , dishonest , entertaining and , ultimate...   \n",
       "146670    The thought of watching this film with an audi...   \n",
       "134201    at this time , with this cast , this movie is ...   \n",
       "146672    The thought of watching this film with an audi...   \n",
       "74656     of the most appealing movie ever made about an...   \n",
       "14964     can such a cold movie claim to express warmth ...   \n",
       "\n",
       "          Sentiment(predict)  Distance  \n",
       "PhraseId                                \n",
       "142370                     4         4  \n",
       "53284                      4         4  \n",
       "37375                      0         4  \n",
       "73472                      4         4  \n",
       "37374                      0         4  \n",
       "117415                     4         4  \n",
       "143437                     4         4  \n",
       "66532                      4         4  \n",
       "130641                     0         4  \n",
       "72813                      4         4  \n",
       "89657                      4         4  \n",
       "99222                      4         4  \n",
       "51504                      0         4  \n",
       "126778                     4         4  \n",
       "142763                     0         4  \n",
       "11777                      4         4  \n",
       "142764                     0         4  \n",
       "36196                      4         4  \n",
       "36195                      4         4  \n",
       "36194                      4         4  \n",
       "11778                      4         4  \n",
       "14831                      4         4  \n",
       "119896                     4         4  \n",
       "89656                      4         4  \n",
       "37376                      0         4  \n",
       "7024                       4         4  \n",
       "35158                      4         4  \n",
       "105911                     0         4  \n",
       "59241                      4         4  \n",
       "42394                      4         4  \n",
       "...                      ...       ...  \n",
       "101006                     4         4  \n",
       "78647                      4         4  \n",
       "21468                      4         4  \n",
       "101007                     4         4  \n",
       "61625                      0         4  \n",
       "78648                      4         4  \n",
       "113299                     4         4  \n",
       "107525                     0         4  \n",
       "16722                      0         4  \n",
       "133345                     0         4  \n",
       "119884                     4         4  \n",
       "149978                     4         4  \n",
       "22212                      4         4  \n",
       "22211                      4         4  \n",
       "92731                      0         4  \n",
       "35159                      4         4  \n",
       "136958                     0         4  \n",
       "35160                      4         4  \n",
       "145063                     4         4  \n",
       "35161                      4         4  \n",
       "96215                      4         4  \n",
       "60437                      4         4  \n",
       "96214                      4         4  \n",
       "130091                     4         4  \n",
       "101017                     4         4  \n",
       "146670                     4         4  \n",
       "134201                     4         4  \n",
       "146672                     4         4  \n",
       "74656                      0         4  \n",
       "14964                      4         4  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본이 훼손되니까 복사해서 사용\n",
    "result = train.copy()\n",
    "result[\"Sentiment(predict)\"] = y_predict\n",
    "# predict한 Sentiment와 train의 실제 Sentiment와의 차이를 통해 모델의 예측차를 확인\n",
    "result[\"Distance\"] = np.abs(result[\"Sentiment\"] - result[\"Sentiment(predict)\"])\n",
    "result = result.sort_values(by=\"Distance\", ascending=False)\n",
    "\n",
    "print(result.shape)\n",
    "result[[\"Phrase\", \"Sentiment(predict)\", \"Distance\"]].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(vocabulary).to_csv(\"vocabular.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceId                                                         7153\n",
       "Phrase                Miyazaki 's nonstop image are so stunning , an...\n",
       "Sentiment                                                             4\n",
       "Phrase(Origin)        Miyazaki 's nonstop images are so stunning , a...\n",
       "Sentiment(predict)                                                    4\n",
       "Distance                                                              0\n",
       "Name: 132656, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stunning 단어 개선\n",
    "\n",
    "result.loc[132656]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=43, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 3, 3, 2, 3, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentiment\n",
       "PhraseId           \n",
       "156061            3\n",
       "156062            3\n",
       "156063            2\n",
       "156064            3\n",
       "156065            3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"SampleSubmission.csv\", index_col=\"PhraseId\")\n",
    "\n",
    "submission[\"Sentiment\"] = predictions\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline-script.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDGClassifier\n",
    "\n",
    "Machine Learning\n",
    "- Supervised Learning(SL)\n",
    "- Unsupervised Learning(UL)\n",
    "- Reinforcement Learning\n",
    "\n",
    "SL: feature(O), label(O)\n",
    "UL: feature(O), label(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "삼성전자 주식 예측 예시\n",
    "- cross validation을 사용할 경우, 시간적인 고려가 되지 않음\n",
    "- ex) 2016년도 주식을 가지고, 2015년도 주식을 예측하는 경우\n",
    "\n",
    "문장의 경우\n",
    "- train 데이터와 test 데이터의 셋이 연관성도 없고 voca set이 다름.\n",
    "- SentenceId 기준으로 중복시키지 않도록 처리\n",
    "\n",
    "0.60 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
