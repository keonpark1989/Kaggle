{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/11 Sentiment Analysis on Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "\"There's a thin line between likably old-fashioned and fuddy-duddy, and The Count of Monte Cristo ... never quite settles on either side.\"\n",
    "\n",
    "The Rotten Tomatoes movie review dataset is a corpus of movie reviews used for sentiment analysis, originally collected by Pang and Lee [1]. In their work on sentiment treebanks, Socher et al. [2] used Amazon's Mechanical Turk to create fine-grained labels for all parsed phrases in the corpus. This competition presents a chance to benchmark your sentiment-analysis ideas on the Rotten Tomatoes dataset. You are asked to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive. Obstacles like sentence negation, sarcasm, terseness, language ambiguity, and many others make this task very challenging.\n",
    "\n",
    "Kaggle is hosting this competition for the machine learning community to use for fun and practice. This competition was inspired by the work of Socher et al [2]. We encourage participants to explore the accompanying (and dare we say, fantastic) website that accompanies the paper:\n",
    "\n",
    "http://nlp.stanford.edu/sentiment/\n",
    "\n",
    "There you will find have source code, a live demo, and even an online interface to help train the model.\n",
    "\n",
    "[1] Pang and L. Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In ACL, pages 115–124.\n",
    "\n",
    "[2] Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Chris Manning, Andrew Ng and Chris Potts. Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative \n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### tsv는 tab 기반\n",
    "\n",
    "# sep => seperate\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase\n",
       "PhraseId                                                               \n",
       "156061          8545  An intermittently pleasing but mostly routine ...\n",
       "156062          8545  An intermittently pleasing but mostly routine ...\n",
       "156063          8545                                                 An\n",
       "156064          8545  intermittently pleasing but mostly routine effort\n",
       "156065          8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\", index_col=\"PhraseId\")\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase(Origin)\"] = train[\"Phrase\"].copy()\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase(Origin)\"] = test[\"Phrase\"].copy()\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can not recommend it'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(phrase):\n",
    "    phrase = phrase.replace(\"ca n't\", \"can not\")\n",
    "    phrase = phrase.replace(\"n't\", \"not\")\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "phrase = \"ca n't recommend it\"\n",
    "\n",
    "clean_text(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A series</td>\n",
       "      <td>A series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>series</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "1         A series of escapades demonstrating the adage ...   \n",
       "2         A series of escapades demonstrating the adage ...   \n",
       "3                                                  A series   \n",
       "4                                                         A   \n",
       "5                                                    series   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "1         A series of escapades demonstrating the adage ...  \n",
       "2         A series of escapades demonstrating the adage ...  \n",
       "3                                                  A series  \n",
       "4                                                         A  \n",
       "5                                                    series  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Phrase\"] = train[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(train.shape)\n",
    "train[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase(Origin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>An</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "156061    An intermittently pleasing but mostly routine ...   \n",
       "156062    An intermittently pleasing but mostly routine ...   \n",
       "156063                                                   An   \n",
       "156064    intermittently pleasing but mostly routine effort   \n",
       "156065           intermittently pleasing but mostly routine   \n",
       "\n",
       "                                             Phrase(Origin)  \n",
       "PhraseId                                                     \n",
       "156061    An intermittently pleasing but mostly routine ...  \n",
       "156062    An intermittently pleasing but mostly routine ...  \n",
       "156063                                                   An  \n",
       "156064    intermittently pleasing but mostly routine effort  \n",
       "156065           intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Phrase\"] = test[\"Phrase\"].apply(clean_text)\n",
    "\n",
    "print(test.shape)\n",
    "test[[\"Phrase\", \"Phrase(Origin)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=15000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words, vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "\n",
    "# max_features: 우리가 단어의 개수를 지정함.\n",
    "# 빈번하게 나오는 단어를 많이 뽑고, 빈도가 낮은 단어는 뽑지 않음\n",
    "# 최대 1000개만 뽑으라고 지정\n",
    "# 문장을 단어로 뽑아줌.\n",
    "# binary option: 해당 단어가 존재유무로 체크\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=15000, ngram_range=(1, 2), binary=True)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer\n",
    "- fit\n",
    "- transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=15000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train[\"Phrase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 15000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<156060x15000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1240382 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 단어의 개수를 \n",
    "\n",
    "X_train = vectorizer.transform(train[\"Phrase\"])\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000', '10', '10 minutes', '10 or', '10 year']"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cacfd0c146c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X_train[0:100].toarray(), columns=vocabulary).head()\n",
    "\n",
    "## row: 전체 데이터\n",
    "## column: voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 15000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<66292x15000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 438933 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test[\"Phrase\"])\n",
    "\n",
    "print(X_test.shape)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhraseId\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "5    2\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = \"Sentiment\"\n",
    "\n",
    "y_train = train[label_name]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=43, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "seed = 43\n",
    "\n",
    "model = SGDClassifier(random_state=seed)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "\n",
    "# print(\"Score = {0:5f}\".format(score))\n",
    "\n",
    "## 기존의 cross_val_score를 두 단계로 나눈 것\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_predict = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "\n",
    "print(y_predict.shape)\n",
    "y_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.57677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_train, y_predict)\n",
    "\n",
    "print(\"Score = {0:.5f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment(predict)</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95524</th>\n",
       "      <td>that 's barely shocking , barely interesting a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85313</th>\n",
       "      <td>the performances by Phifer and Black are ultim...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119288</th>\n",
       "      <td>passes time until it 's time for an absurd fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73384</th>\n",
       "      <td>It 's the element of condescension , as the fi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136958</th>\n",
       "      <td>as an intellectual exercise -- an unpleasant d...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96214</th>\n",
       "      <td>a chore to sit through -- despite some first-r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117378</th>\n",
       "      <td>Every now and again , a movie comes along to r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59241</th>\n",
       "      <td>manipulating our collective fear without besto...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64040</th>\n",
       "      <td>This is a fragmented film , once a good idea t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64041</th>\n",
       "      <td>is a fragmented film , once a good idea that w...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59223</th>\n",
       "      <td>post-September 11 , `` The Sum Of All Fears ''...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59222</th>\n",
       "      <td>... post-September 11 , `` The Sum Of All Fear...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89657</th>\n",
       "      <td>profane and exploitative as the most offensive...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89656</th>\n",
       "      <td>, profane and exploitative as the most offensi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62509</th>\n",
       "      <td>especially the frank sex scenes -RRB- ensure t...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110715</th>\n",
       "      <td>` In this poor remake of such a well loved cla...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98295</th>\n",
       "      <td>had so much fun dissing the film that they did...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113467</th>\n",
       "      <td>is well below expectations .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113466</th>\n",
       "      <td>Below is well below expectations .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56607</th>\n",
       "      <td>'s never a dull moment in the giant spider inv...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127102</th>\n",
       "      <td>10 minutes into the film you 'll white-knuckle...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119894</th>\n",
       "      <td>again that the era of the intelligent , well-m...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143397</th>\n",
       "      <td>is not Edward Burns ' best film</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119884</th>\n",
       "      <td>arrived for an incongruous summer playoff , de...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90786</th>\n",
       "      <td>taken one of the world 's most fascinating sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37143</th>\n",
       "      <td>Only two-fifths of a satisfying movie experience</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75207</th>\n",
       "      <td>could have used my two hours better watching B...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38915</th>\n",
       "      <td>Men in Black II achieves ultimate insignifican...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124280</th>\n",
       "      <td>, others will find their humor-seeking dollars...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85477</th>\n",
       "      <td>K-19 will not go down in the annals of cinema ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90463</th>\n",
       "      <td>The story ... is inspiring , ironic , and reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127570</th>\n",
       "      <td>can not properly called acting -- more accurat...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110255</th>\n",
       "      <td>This is a nervy , risky film , and Villeneuve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35967</th>\n",
       "      <td>Painful , horrifying and oppressively tragic ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113119</th>\n",
       "      <td>this supposedly funny movie</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124283</th>\n",
       "      <td>will find their humor-seeking dollars best spe...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140202</th>\n",
       "      <td>go down as one of the all-time great apocalyps...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140201</th>\n",
       "      <td>might go down as one of the all-time great apo...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140200</th>\n",
       "      <td>might go down as one of the all-time great apo...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95525</th>\n",
       "      <td>'s barely shocking , barely interesting and mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140263</th>\n",
       "      <td>The original was not a good movie but this rem...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70805</th>\n",
       "      <td>Maggie Smith as the Ya-Ya member with the O2-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110305</th>\n",
       "      <td>the year 's worst cinematic tragedies</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90784</th>\n",
       "      <td>he 's taken one of the world 's most fascinati...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110481</th>\n",
       "      <td>When a movie has stuck around for this long , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46691</th>\n",
       "      <td>all the story gives us is flashing red lights ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14288</th>\n",
       "      <td>is an insultingly inept and artificial examina...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76745</th>\n",
       "      <td>Unfunny comedy with a lot of static set ups , ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76746</th>\n",
       "      <td>Unfunny comedy with a lot of static set ups , ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92884</th>\n",
       "      <td>predominantly amateur cast is painful to watch</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101559</th>\n",
       "      <td>A deliciously nonsensical comedy about a city ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151694</th>\n",
       "      <td>manages to bleed it almost completely dry of h...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151695</th>\n",
       "      <td>manages to bleed it almost completely dry of h...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151697</th>\n",
       "      <td>bleed it almost completely dry of humor , verv...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14964</th>\n",
       "      <td>can such a cold movie claim to express warmth ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117510</th>\n",
       "      <td>is how its makers actually seem to understand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105860</th>\n",
       "      <td>Salma goes native and she 's never been better...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105859</th>\n",
       "      <td>Salma goes native and she 's never been better...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77862</th>\n",
       "      <td>Delight your senses and crash this wedding !</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82697</th>\n",
       "      <td>This is one of the biggest disappointments of ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Phrase  \\\n",
       "PhraseId                                                      \n",
       "95524     that 's barely shocking , barely interesting a...   \n",
       "85313     the performances by Phifer and Black are ultim...   \n",
       "119288    passes time until it 's time for an absurd fin...   \n",
       "73384     It 's the element of condescension , as the fi...   \n",
       "136958    as an intellectual exercise -- an unpleasant d...   \n",
       "96214     a chore to sit through -- despite some first-r...   \n",
       "117378    Every now and again , a movie comes along to r...   \n",
       "59241     manipulating our collective fear without besto...   \n",
       "64040     This is a fragmented film , once a good idea t...   \n",
       "64041     is a fragmented film , once a good idea that w...   \n",
       "59223     post-September 11 , `` The Sum Of All Fears ''...   \n",
       "59222     ... post-September 11 , `` The Sum Of All Fear...   \n",
       "89657     profane and exploitative as the most offensive...   \n",
       "89656     , profane and exploitative as the most offensi...   \n",
       "62509     especially the frank sex scenes -RRB- ensure t...   \n",
       "110715    ` In this poor remake of such a well loved cla...   \n",
       "98295     had so much fun dissing the film that they did...   \n",
       "113467                         is well below expectations .   \n",
       "113466                   Below is well below expectations .   \n",
       "56607     's never a dull moment in the giant spider inv...   \n",
       "127102    10 minutes into the film you 'll white-knuckle...   \n",
       "119894    again that the era of the intelligent , well-m...   \n",
       "143397                      is not Edward Burns ' best film   \n",
       "119884    arrived for an incongruous summer playoff , de...   \n",
       "90786     taken one of the world 's most fascinating sto...   \n",
       "37143      Only two-fifths of a satisfying movie experience   \n",
       "75207     could have used my two hours better watching B...   \n",
       "38915     Men in Black II achieves ultimate insignifican...   \n",
       "124280    , others will find their humor-seeking dollars...   \n",
       "85477     K-19 will not go down in the annals of cinema ...   \n",
       "...                                                     ...   \n",
       "90463     The story ... is inspiring , ironic , and reve...   \n",
       "127570    can not properly called acting -- more accurat...   \n",
       "110255    This is a nervy , risky film , and Villeneuve ...   \n",
       "35967     Painful , horrifying and oppressively tragic ,...   \n",
       "113119                          this supposedly funny movie   \n",
       "124283    will find their humor-seeking dollars best spe...   \n",
       "140202    go down as one of the all-time great apocalyps...   \n",
       "140201    might go down as one of the all-time great apo...   \n",
       "140200    might go down as one of the all-time great apo...   \n",
       "95525     's barely shocking , barely interesting and mo...   \n",
       "140263    The original was not a good movie but this rem...   \n",
       "70805     Maggie Smith as the Ya-Ya member with the O2-t...   \n",
       "110305                the year 's worst cinematic tragedies   \n",
       "90784     he 's taken one of the world 's most fascinati...   \n",
       "110481    When a movie has stuck around for this long , ...   \n",
       "46691     all the story gives us is flashing red lights ...   \n",
       "14288     is an insultingly inept and artificial examina...   \n",
       "76745     Unfunny comedy with a lot of static set ups , ...   \n",
       "76746     Unfunny comedy with a lot of static set ups , ...   \n",
       "92884        predominantly amateur cast is painful to watch   \n",
       "101559    A deliciously nonsensical comedy about a city ...   \n",
       "151694    manages to bleed it almost completely dry of h...   \n",
       "151695    manages to bleed it almost completely dry of h...   \n",
       "151697    bleed it almost completely dry of humor , verv...   \n",
       "14964     can such a cold movie claim to express warmth ...   \n",
       "117510    is how its makers actually seem to understand ...   \n",
       "105860    Salma goes native and she 's never been better...   \n",
       "105859    Salma goes native and she 's never been better...   \n",
       "77862          Delight your senses and crash this wedding !   \n",
       "82697     This is one of the biggest disappointments of ...   \n",
       "\n",
       "          Sentiment(predict)  Distance  \n",
       "PhraseId                                \n",
       "95524                      4         4  \n",
       "85313                      0         4  \n",
       "119288                     4         4  \n",
       "73384                      4         4  \n",
       "136958                     0         4  \n",
       "96214                      4         4  \n",
       "117378                     4         4  \n",
       "59241                      4         4  \n",
       "64040                      4         4  \n",
       "64041                      4         4  \n",
       "59223                      4         4  \n",
       "59222                      4         4  \n",
       "89657                      4         4  \n",
       "89656                      4         4  \n",
       "62509                      0         4  \n",
       "110715                     4         4  \n",
       "98295                      4         4  \n",
       "113467                     4         4  \n",
       "113466                     4         4  \n",
       "56607                      0         4  \n",
       "127102                     0         4  \n",
       "119894                     4         4  \n",
       "143397                     4         4  \n",
       "119884                     4         4  \n",
       "90786                      4         4  \n",
       "37143                      4         4  \n",
       "75207                      4         4  \n",
       "38915                      4         4  \n",
       "124280                     4         4  \n",
       "85477                      4         4  \n",
       "...                      ...       ...  \n",
       "90463                      0         4  \n",
       "127570                     4         4  \n",
       "110255                     0         4  \n",
       "35967                      0         4  \n",
       "113119                     4         4  \n",
       "124283                     4         4  \n",
       "140202                     0         4  \n",
       "140201                     0         4  \n",
       "140200                     0         4  \n",
       "95525                      4         4  \n",
       "140263                     4         4  \n",
       "70805                      0         4  \n",
       "110305                     4         4  \n",
       "90784                      4         4  \n",
       "110481                     0         4  \n",
       "46691                      4         4  \n",
       "14288                      4         4  \n",
       "76745                      4         4  \n",
       "76746                      4         4  \n",
       "92884                      4         4  \n",
       "101559                     0         4  \n",
       "151694                     4         4  \n",
       "151695                     4         4  \n",
       "151697                     4         4  \n",
       "14964                      4         4  \n",
       "117510                     0         4  \n",
       "105860                     0         4  \n",
       "105859                     0         4  \n",
       "77862                      0         4  \n",
       "82697                      4         4  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본이 훼손되니까 복사해서 사용\n",
    "result = train.copy()\n",
    "result[\"Sentiment(predict)\"] = y_predict\n",
    "# predict한 Sentiment와 train의 실제 Sentiment와의 차이를 통해 모델의 예측차를 확인\n",
    "result[\"Distance\"] = np.abs(result[\"Sentiment\"] - result[\"Sentiment(predict)\"])\n",
    "result = result.sort_values(by=\"Distance\", ascending=False)\n",
    "\n",
    "print(result.shape)\n",
    "result[[\"Phrase\", \"Sentiment(predict)\", \"Distance\"]].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(vocabulary).to_csv(\"vocabular.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceId                                                         7153\n",
       "Phrase                Miyazaki 's nonstop images are so stunning , a...\n",
       "Sentiment                                                             4\n",
       "Phrase(Origin)        Miyazaki 's nonstop images are so stunning , a...\n",
       "Sentiment(predict)                                                    4\n",
       "Distance                                                              0\n",
       "Name: 132656, dtype: object"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stunning 단어 개선\n",
    "\n",
    "result.loc[132656]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=43, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 3, 3, 2, 3, 2])"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions.shape)\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156061</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156062</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156063</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156064</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156065</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentiment\n",
       "PhraseId           \n",
       "156061            3\n",
       "156062            3\n",
       "156063            2\n",
       "156064            3\n",
       "156065            3"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"SampleSubmission.csv\", index_col=\"PhraseId\")\n",
    "\n",
    "submission[\"Sentiment\"] = predictions\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"baseline-script.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDGClassifier\n",
    "\n",
    "Machine Learning\n",
    "- Supervised Learning(SL)\n",
    "- Unsupervised Learning(UL)\n",
    "- Reinforcement Learning\n",
    "\n",
    "SL: feature(O), label(O)\n",
    "UL: feature(O), label(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
